**ğŸ“˜ Local Offline AI Developer Assistant**

A fully offline, privacy-focused AI Developer Assistant built using DeepSeek Coder 1.3B and Ollama.
This tool can explain code, debug errors, search your entire project, read files, analyze functions, and answer coding questions all running locally on your machine without internet.



**ğŸš€ Features**

ğŸ”¹ 1. Code Explanation

Explains any Python/JS/TS/text file

Summarizes logic, functions, classes

Highlights key operations and structure

ğŸ”¹ 2. Debugging Assistance

Analyzes code

Detects potential bugs

Explains why an error occurs

Suggests fixes with clear reasoning

ğŸ”¹ 3. Project-wide Code Search

Search for:

functions

variables

patterns

keywords

Shows file name + line number + matching text

ğŸ”¹ 4. Function Definition Locator

Find exactly where a function is defined inside the project.

ğŸ”¹ 5. File System Tools

Read files

List project files

Show metadata (size, extension, location)

Skip unwanted folders (__pycache__, .git, etc.)

ğŸ”¹ 6. Ask AI Questions

Ask general programming questions or questions with file context.

ğŸ”¹ 7. Completely Offline

No API keys

No cloud

No external dependency

100% privacy

All inference runs inside Ollama locally




**ğŸ§  Why DeepSeek Coder 1.3B?**

DeepSeek Coder 1.3B was selected over Gemma-3-270M because:

Better code understanding

More accurate debugging

More reliable explanations

Larger training data

Still small enough to run offline on CPU

Excellent for Python + general coding tasks

This model gives high-quality output while staying fast and lightweight.




| Component                        | Purpose                       |
| -------------------------------- | ----------------------------- |
| **Python 3.10+**                 | Main CLI logic                |
| **Ollama**                       | Local LLM runtime             |
| **DeepSeek Coder 1.3B**          | Offline code-focused AI model |
| **Colorama**                     | Colored CLI output            |
| **Model Context Protocol (MCP)** | Tool wrapper system           |
| **Custom Tools**                 | File operations & code search |





**Project Structure **
Local-Offline-AI-Developer-Assistant/
â”‚â”€â”€ cli.py                # Command-line interface
â”‚â”€â”€ ollama_client.py      # Communication with DeepSeek Coder
â”‚â”€â”€ mcp_server.py         # (Optional) MCP server file
â”‚â”€â”€ config.json           # Allowed extensions, excluded folders
â”‚â”€â”€ requirements.txt      # Python dependencies
â”‚â”€â”€ test.py               # Sample file for testing
â”‚â”€â”€ tools/
â”‚   â”œâ”€â”€ file_ops.py       # File reading/listing helper
â”‚   â””â”€â”€ search.py         # Project-wide code search
â””â”€â”€ .gitignore            # Ignore unnecessary files




**ğŸ”’ Offline Privacy Guarantee**

This project runs 100% on your local system.
No data is sent to any server.
No API keys or internet required.
Perfect for confidential codebases.



**ğŸ Conclusion**

This project demonstrates that even a lightweight 1.3B model can serve as a powerful offline coding assistant.
It delivers useful code explanations, debugging, search, and project understandingâ€”all without internet, and entirely on your local machine.
